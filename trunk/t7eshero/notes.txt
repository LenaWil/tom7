
MIDI File Encoding                                         31 Dec 2007

The track name encodes what kind of track it is, and other information
that is global to that track.

The first character determines the track type.

 + means a music track.
    The next character determines the instrument used:
       W: sawtooth
       Q: square
       S: sine
       N: noise

... more track types here (e.g. score)

  ! means a score track. 
     The next character determines the difficulty level:
       E: Easy
       H: Hard
       X: Expert
       R: Real

    These contain notes C5-E5 (MIDI 60-64)
    corresponding to fingers 0-4 respectively.

    In the score, a note with velocity < 64 is considered hammered.

    (These scores can be generated automatically with genscore,
     but they should be hand-tweaked!)

----------------------------------------------------------------------
                                                            5 Apr 2008

Hack session.

To get this minimally useful I'm just gonna go for it. For the online
dynamic programming algorithm below, I'll just create the entire matrix
in RAM and fill it in. We pay |score events| space and time for every
input event, but that's fairly small (a few hundred events in a typical
song).

The unknown to me is how to make the scoring algorithm interact with
the graphical and audio show in a fun way. Specifically: the score is
currently just a separate MIDI track with nothing to connect its
events to the audio events. If we miss a note, or release early, we
should be able to modulate the associated audio events. Because of the
way we're using the MIDI format to store the audio and score, there's
no obvious way to store the connection between a score event and the
audio note(s) it corresponds to. However, the way we're currently
generating scores automatically leaves a 1-1 mapping between notes
that can be recovered as long as we know the input tracks that were
used to generate the score in the first place. So let's store those
and make the connection that way.

Fine, so we have the matching matrix and we have the notes of the
score flying by. How are they connected? Let's give each score event
a reference cell. It can have some states:

  Future -- maybe being drawn, but it is outside the matching window
  (into the future) and therefore is not playing and has no special
  status.

  Live -- inside the matching window. Can be activated. We don't want
  the note to play as soon as it enters the window, of course.
  (Does it matter? We might want to draw them different or something.)

  Playing -- a note that is actually playing, having crossed the nut.
  As long as we are on a streak, the sound begins. Once it goes out
  of the matching window without being matched (or when we otherwise
  know it can't be matched), we can Fail it which causes it to stop
  playing and emit a bad sound.

  NotPlaying -- a note that isn't playing, but has crossed the nut.
  When we're off streak, no input means no sound for those events.
  If it is successfully matched when we exit the matching window,
  then we can start playing it.
  If it passes out of the matching window or we otherwise know it
  can't be matched, then we can Fail it. 

  All notes that are on the other side of the scoring window (Past)
  are either Played or Failed.


Point is: Score events have a state, which is uninteresting until they
enter the match window. At that point the state becomes volatile, and
we are fudging the audio and display of it based on whether we are on
streak or not (which keeps good success and fail flows but can produce
the wrong results on edges, but this is necessary on account of our
inability to predict the future perfectly!) When they exit the matching
window their fates are sealed as Played or Failed. 

In some of these states we need to maintain a reference to the
associated audio/video event so that we can stop or start it. A
reference will suffice, most likely.

----------------------------------------------------------------------

Generating a Score                                         11 Mar 2008

For maximum scalability and hack value, we should be able to create a
score automatically from a MIDI file. There are a number of compounding
issues:

 A  There are different "difficulty" levels with different requirements:
     for "real" there ought to be one score event for every note/chord in
     the original. For "easy" we only ought to use the lowest three
     fingers, and never any really fast notes, etc.

 B  The original MIDI files have a much wider range in note values than
     we have fingers in the score.

 C  Most songs consist of repeating phrases, which ought to be played
     the same way each time they are encountered--regardless of context.

 D  The MIDI music can do things that are not allowed in the score, such
     as beginning one note event while others are already active. (We
     do non-standardly allow a chord whose notes trail off at different
     times.)

 E  The MIDI files do not come from guitars and are often awkward to
     play on real guitars.

 F Even though we might need to use a different finger for two
     occurrences of a given note, we should never do so for
     consecutive ocurrences.

Some of these are dealt with easily. For E, we don't really care (in
fact we explicitly want Real mode to be ridiculous) except that we
want the guitar part to be fun moreso than realistic. (Therefore what
we really want is a model of "plausible" guitar movements
corresponding to the notes, and to produce a good member of the
model.) For A, we just need to build a model that is parameterized by
the number of fingers allowed (and other requirements).

Additionally, we should feel free to implement an expensive algorithm
(taking several minutes) since we run this process off-line.

For D, we should perform some pre-processing to normalize the MIDI
into a form that we can assume some things about. This would be one of
the things we'd want to get rid of. We might also want to detect notes
that are short enough to be considered "individual" notes, and set
those to some canonical length (1 tick). (Really, during this phase
there's no reason to complicate matters by having both "individual"
and "long" notes, since we have to solve the problem in generality for
"long" notes. Let's just treat that as a presentational issue.)

Okay so here we go, a series of non-overlapping sonemes, spread out
over the entirety of MIDI note space. We just need to lay those out on
the 5-note scale. Any allocation is legal, but some have better scores
than others. 

Let's not go overboard. We'll make one simplifying assumption, which is
that we only make individual measures optimal, given the context in
which they occur originally. Split the song into (unique) measures.
Process them in topological order. To process:

 * try all(!) assignments of sonemes to notes for a measure. This is
   naively exponential time, though most measures don't have more than
   12 or so notes in them (which is about the upper limit that we
   could process within reason..) However, since the cost dependencies
   are local, dynamic programming will probably work. Find the best one
   and save it (forever) for that measure.

 * Whenever we do a measure M, take the argmax(min(Mi, M)) over the Mi
   that immediately precede M in the MIDI. That is, we want to avoid
   very awkward transitions from measure to measure, if possible.
   However, we don't care too much about optimizing these globally.
   It is assumed that the size of {Mi} is small, since this is a
   multiplicative factor over how much work we do for M.


The goodness of a note assignment is the negation of its badness, which
is easier to define. The badness is the sum of penalties, which are
assessed as follows.

 * For a pair of consecutive sonemes N1 N2 in the MIDI, where N1 < N2,
   if S1 = S2 then score -3. If S1 > S2 then score -2.

 * Likewise for N1 > N2.

 * If N1 = N2 and S1 <> S2, score -10. (maybe higher! This is really really bad)

 * The > and < are defined in the obvious way for individual notes. For
   chords, we do something a little more complicated? (esp. since there
   are 5cN different ways to configure a N-note chord, hrmmm.)

 * For easy, medium, hard, and expert modes score a penalty for really
   reachy chords. (Which should probably increase as the level is easier.)


----------------------------------------------------------------------

Responding to Input                                        27 Dec 2007
or, Generalized Tom 7 Entertainment System Hero is complexity-class-complete


In this game there is a score of music and user input that attempts to
match the score in real time. The score and input take place on a
5-tone scale, though the number of tones is not really important for
this discussion. The musical score is a time-indexed sequence of
sonemes, which are individual notes or chords. (The way we match a
soneme is different based on whether it is a note or a chord.) Sonemes
have (possibly zero) duration and can optionally be "hammered." (A
hammered soneme can be matched by edge effects in user input, and is
the main source of difficulty in matching.) The user's input is a
time-indexed sequence of events. An event is either a note-on, a
note-off, or a commit.

* Ambiguity in subsequence matching

Let us begin by ignoring durations and hammered sonemes. Our job is to
take the score and input and decide which sonemes have been
successfully matched. For this simplified problem, we track the on/off
status of each note in the input and treat the 'commit' event as an
impulse playing those notes that are currently on. We wish to allow
the player some timing error, so we allow commitments to occur
slightly before or after a target soneme. However, sonemes must be
played in the proper order--even if their rearrangement would make
them individually legal within the time error window. For example,
suppose we allow 10 frames of error in either direction, and take the
following score:

  A  @  100
  B  @  110

With these commitments from the user:

  B @ 104
  A @ 106

Both events take place within 10 frames of their corresponding sonemes
in the score, but because they occur out of order, we can only pick
one of the two to match. Supposing that the error window is
arbitrarily large, then the problem becomes longest common subsequence
matching, which is O(|score| * |input|) using they dynamic programming
algorithm (but apparently there is a faster algorith for that). Can we
avoid considering the error window by preprocessing? Perhaps we could
imagine that we living in an extended alphabet that is constantly
changing as we pass through the string. For instance, suppose that the
input score is originally

  |     |     |     |     |     |
  A  B  B  B  A  A  A  A  B  A  B ...

where the bars represent the width of the error window. Then if the
input is

  A A B B   B AB  B A  A   B  AAA ...

we rename characters so that no character matches one outside its
error window. But is that even possible? We'd like to rename the first
B in the score so that it can't apparently match the second B in the
input:

  |     |     |     |     |     |
  A  C  B  B  A  -  -  -  -  -  - ...
  - - - ?   B --  - -  -   -  --- ...

.. but then we'd have to rename the first B in the input (which could
match it), which would make it unable to match the ones that follow.
So this plan does not work--we need to think about the error window.
But we can do it like this: treat the alphabet as consisting of tuples
of note and time, and then take "equality" to be "equality within
epsilon" (this is not transitive, but that is not really important for
these algorithms). In the dynamic programming algorithm for solving
maximum common subsequence, for example, we are always comparing
equality between specific positions in the input strings. (We don't
even require symmetry or reflexivity in this sense; the left and right
side of the equality operator don't even need to be the same type!)

* Matching a soneme

So, our first step is to define the same-soneme predicate. The rules
of soneme matching are meant to simulate the way a guitar is played.
Therefore, when playing an individual note, we allow any notes (frets)
below it to be held, since those do not affect the pitch on a guitar.

        score       input
 same(Note N @ t, Commit (N1, ..., Nn N) @ t')
   if N1 < N, ... Nn < N and |t-t'| <= epsilon

Because chords are meant to simulate the specific hand shape used to
play them, they must be played exactly.

  same(Chord (N1, ... Nn) @ t, Commit (N1, ..., Nn) @ t')
   if |t-t'| <= epsilon

* Penalties

One thing to notice is that as the user's input grows in length
(density), the size of the longest common subsequence can only grow.
This means that the player is never penalized for extraneous input,
which is clearly wrong.

We can treat this easily by computing not the length of the sequence
but a point value that depends on a number of factors, such as the
number of missed notes. This is a lot like edit distance, where an
edit distance of 0 corresponds to perfect play:

   inputs...

 s 0123456789
 c 1.
 o 2 .
 r 3  .
 e 4
 . 5
 : 6

An "insertion" (from score->inputs) is an extraneous commit event, and
a "deletion" is a missed note. A "modification" is the wrong note
played (both an insertion and a deletion). Each is assessed a penalty.
This also allows us to optionally not penalize insertions of certain
events, which we will need to treat hammered notes.

* Hammered sonemes

Sonemes can also be triggered by note-on and note-off events, if they
are specially marked as "hammered." (Hammering refers to the act of
hitting the guitar string with the fretting finger, causing it to
vibrate or continue to vibrate. It also includes a pull-off, where
the finger being pulled off a fret plucks the string and thereby
plays the note fretted by the finger below it.) Let's first discuss
hammer-on notes. The rules are as follows.

 - only sonemes that are marked as "hammered" in the score 
   can be played this way.
 - only individual notes can be marked as "hammered", because
   otherwise we need to coordinate multiple note-on events at
   different times in order to trigger a hammered chord.
     (this would be possible, but is not that common in real
      guitar playing, anyway)
 - A hammered note is triggered by a note-on event.
 - A hammered soneme must follow a correctly played soneme 
     (it must be part of a "streak", where every streak starts
      with a commit event)
 - A note-on event that does not correctly play a note is not
   penalized, but it stops the streak.
 - Note-off events are never penalized and never stop the streak.
     (they can also play hammered notes as pull-offs, which is
      discussed below.)

To use the dynamic programming technique to allow for hammered notes,
we must extend the matching predicate and expand the information
included in the "distance".

   inputs...

 s 0123456789
 c 1.
 o 2 ab
 r 3 cX
 e 4
 . 5
 : 6

Consider the position X when the input is note-on Z and the score
contains a hammered note Z at that position. We can get to X from
positions a, b, and c. From b to X corresponds to a missed note,
because we advance the position in the score without using any input.
In this case, we terminate the streak in X. From c corresponds to
ignoring the input but not advancing the score. This terminates the
streak, since it is a note-on event, but it does not cause a miss.
Coming from a, if 'a' is on a streak, then we continue the streak and
succeed in playing the note. If 'a' is not on streak, then we cannot
make this transition.

Therefore, each entry in the table takes the form

   { misses : int, streak : bool }

We compare these tuples lexicographically, with misses being the major
factor. That is, we prefer to be on a streak if possible, but the more
important thing is a low number of sonemes missed. Let's consider the
following cases in the dynamic programming algorithm now. Each takes
the form

    E
  ...
  :ab
 S.cX

Where E is the input event and S is the score event (indexed by time).
As above, a, b, and c are the already-computed entries in the matrix
adjacent to this one. Let's write a.n for the notes_hit component of a
and a.s for the streak component. Then we have the following cases:

If E is a Commit event and same(S, E) then

  X = max [{ misses = a.m,     streak = true  }, (* hit *)
           { misses = b.m + 1, streak = false }, (* skip *)
           { misses = c.m + 1, streak = false }, (* miss *)
           ]

If not same(S, E) then

  X = max [{ misses = a.m + 1, streak = false }, (* wrong *)
           { misses = b.m + 1, streak = false }, (* skip *)
           { misses = c.m + 1, streak = false }, (* miss *)
           ]

(For commit, we have little choice but to hit the correct soneme.)

If E is a Note-on(N) event and S is Note(N') where N' is hammered,
then

  X = max [if a.s  and  N "=" N' (* must be on streak, same note *)
           then { misses = a.m,     streak = true  }  (* hit *)
           else { misses = a.m + 1, streak = false }, (* miss *)
           { misses = b.m + 1, streak = false },      (* skip *)
           { misses = c.m,     streak = false }       (* extraneous *)
           ]

The interesting case is for a, where we must be on a streak in order
to accept this note as a match. For c, we do not penalize extraneous
note-on events but they interrupt the streak. If E is a Note-off(N)
event (Since this is a pull-off, N here refers to the highest finger
beneath the note that went off, not the note itself.) and S is
Note(N') where N' is hammered, then

  X = max [if a.s  and  N "=" N' (* must be on streak, same note *)
           then { misses = a.m,     streak = true  }  (* hit *)
           else { misses = a.m + 1, streak = false }, (* miss *)
           { misses = b.m + 1, streak = false },      (* skip *)
           { misses = c.m,     streak = c.s }         (* extraneous *)
           ]

Note-off events are the same, but if they are extraneous (c) they do
not interrupt the streak.

* Note durations

We also have note durations, but these are treated independently of
the matching algorithm. As each note in the score passes by in real
time, if the player is fingering a matching input at that time (chord,
note, etc.) then that note is assigned increasing point values for
each unit of time passed. Whether the bonus points assigned to this
note are ultimately given to the player is determined by the matching
algorithm above. This is because we must start giving bonus points to
the player if he is holding the chord when the long note begins, but
we might not know if the note is going to be counted until the matching
algorithm leaves its window (below).

* On-line matching

The final issue is a confounding one. The game is played by scrolling
the score and accepting user input as the song plays, but the algorithm
we described needs the entire input and score in order to compute the
match! We need to be able to give immediate feedback to the player,
because this is part of the "feel" of the game. Up-to-date status is
important for other features, like failing a song when the local
match is too poor, or activating Star Power, etc. This means that we
desire an "on-line" version of the algorithm.

The reason that we are not totally screwed is that the epsilon
parameter places a very tight constraint on matching that allows us
to solve the exact problem on-line. Intuitively, a note played at
the beginning of the song cannot match a note in the score at the
end of the song (or any other note outside of the window defined by
epsilon), and therefore we do not need to consider such pairs when
determining the match.

Imagine the full n*m grid representing the score (x axis) and input
(y axis). 

# Solve the problem exactly by optimizing the matching problem to
# take into account epsilon? (Does latency always follow as a
# function of epsilon?)

--------------------------------------------------

Interesting: SDL patch that allows arbitrary scaling of video:
http://garni.ch/dosbox/
